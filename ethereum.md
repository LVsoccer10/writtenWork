## Essay for Ethereum Foundation Internship Applications

<p align="justify"> The growing pervasiveness of high-dimensional data requires a constant evolution in the methodologies and analytical tools statisticians, computer scientists, and applied scientists use. As much of real-world data–in social networks, financial markets, genomics, natural language processing–often exhibit intricate and non-linear structures, it makes sense to use techniques that can extend beyond linear settings. Non-linear dimensionality reduction (NLDR) techniques have emerged as useful methods with which to explore complex data. NLDR techniques have become valuable in enabling computational scientists to identify unique patterns or features that may be difficult to detect with linear methods. I am interested in leveraging my experience with NLDR techniques to develop new frameworks for machine learning and economic applications. </p>

<p align="justify"> I find it interesting that recent advances in artificial intelligence, machine learning, and statistics reflect some of the principles in Prof. John Holland’s work on Complex Adaptive Systems. I was first introduced to this work in a Stanford Online High School course (“Methodology of Science–Biology”), which explored the intersection of biology/ecology and statistics. Prof. Holland argued that for systems to function like simulators, they must be adaptive, capable of modifying their behavior and performance with newly acquired information about their environment. The idea that, rather than rely on pre-programmed rules, adaptive systems use feedback loops to improve and optimize their performance appears naturally in machine learning and computational statistics. In my internship at ANSYS this summer, I got first-hand experience with machine learning models in engineering. Using years’ worth of data (results of engineering simulations across multiple fields and applications), the models estimated the computational and cost resources required for engineering simulations (before those simulations were run). The models adapted to the engineering context (for each simulation), to new simulation features, and to changes in the computational environment to improve their predictions. Parts of the models related to Markov Chain Monte Carlo (MCMC) sampling and adaptive bootstrapping, which were covered in my computational statistics class. </p>

<p align="justify"> Since last year, I have been exploring a certain type of adaptive process working with Prof. Yoav Freund on a new NLDR technique. Motivated by electrical circuits in which potential energy (voltage) gets minimized across a network of points, Prof. Freund and his coauthors have proposed a grounded resistor graph as a dynamic, localized method for representing the structure of high-dimensional data. (A grounded resistor graph is a weighted, undirected graph in which the source vertex is replaced by a source region and the sink vertex is replaced by an added universal ground node, which is connected to all other vertices.) Unlike NLDR techniques which tend to apply global constraints on the entire graph as one, this method uses localized voltage functions: the strategy reduces complexity by dividing the data cloud graph into smaller regions and adapting to the topology of those regions. This localized process offers potential for parallelization, addressing computational and storage costs and scalability issues which can plague traditional NLDR techniques (e.g. diffusion maps, Laplacian eigenmaps). </p>

<p align="justify"> In our work with Prof. Freund, we have been trying to identify the most representative landmarks for the grounded resistor graph (nodes in the source region). Instead of assigning a predetermined number of landmarks, we have been applying an iterative process by which landmarks are chosen according to the underlying structure of the data. The process initially selects a set of candidate landmarks by clustering the original high-dimensional data graph into regions. The grounded resistor graph is distilled down to a collection of centroids, each associated with a probability for a data point belonging to the region of that centroid. The evaluation of how well this resulting graph preserves structure is done by computing the localized voltage solutions on the graph: the localized solutions converge to a non-trivial solution, and any significant deviation from that convergence value suggests an ineffective representation of the data (in a sense, the objective is “opposite” from that of projection pursuit). The process then uses those localized solutions to determine whether the candidate landmarks best reflect the structure of the original data, and if they do not, the process updates the selection of the landmark to a new, improved set. This adaptive process draws on principles from supervised learning and optimization (Voronoi diagrams, k-means clustering). In iteratively selecting landmarks based on how well they depict the data’s inherent dependencies, the grounded resistor graph can suitably account for the data complexities and the generated voltage functions are not restricted to satisfying global criteria (as with Laplacian eigenmaps with forced orthogonality) or to behaving trivially in larger, more involved settings (as with effective resistance). In this way, the graph can yield more representative low-dimensional embeddings of the original data. </p>

<p align="justify"> I am interested in rigorously exploring other, challenging problems that involve similar adaptive processes. Whether I am trying to help design scalable algorithms, optimize resource allocation, or work on novel frameworks for machine learning and economic theory, I am motivated to continue exploring how best to apply mathematical and computational tools to solve complicated problems in the intersection of fields. I think my experience working with adaptive processes and computational frameworks will help me contribute to better understanding and designing incentive structures. I would cherish the opportunity to work on some of the interesting problems the Ethereum Foundation is actively tackling while also getting the chance to learn from and collaborate with leading researchers in the field. </p>


